Homework 2
================
Yuanxin Zhang

This is my solution to Homework 2.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

# Question 1

### Part 1: Read and clean the Mr. Trash Wheel sheet

1)  Specify the sheet in the Excel file and to omit non-data entries
2)  Use reasonable variable names
3)  Omit rows that do not include dumpster-specific data
4)  Round the number of sports balls to the nearest integer and converts
    the result to an integer variable

<!-- end list -->

``` r
trashwheel_df = 
    read_xlsx(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
    )
```

### Part 2: Read and clean precipitation data for 2017 and 2018

1)  For each, omit rows without precipitation data and add a variable
    year.

<!-- end list -->

``` r
precip_2017 = 
    read_xlsx(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2017 Precipitation",
        skip = 1) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2017) %>% 
    relocate(year)

precip_2018 = 
    read_xlsx(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2018 Precipitation",
        skip = 1) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2018) %>% 
    relocate(year)
```

2)  Combine precipitation datasets and convert month to a character
    variable.

<!-- end list -->

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )

precip_df = 
    bind_rows(precip_2017, precip_2018)

precip_df =
    left_join(precip_df, month_df, by = "month")

precip_df %>% select(year, month = month_name,total)
```

    ## # A tibble: 24 x 3
    ##     year month     total
    ##    <dbl> <chr>     <dbl>
    ##  1  2017 January    2.34
    ##  2  2017 February   1.46
    ##  3  2017 March      3.57
    ##  4  2017 April      3.99
    ##  5  2017 May        5.64
    ##  6  2017 June       1.4 
    ##  7  2017 July       7.09
    ##  8  2017 August     4.44
    ##  9  2017 September  1.95
    ## 10  2017 October    0   
    ## # … with 14 more rows

### Part 3: Write a paragraph about these data

Mr. Trash Wheel dataset contains information from the Mr. Trash Wheel
trash collector in Baltimore, Maryland. As trash enters the inner
harbor, the trash wheel collects that trash, and stores it in a
dumpster. The dataset contains information on year, month, and trash
collected, include some specific kinds of trash. There are a total of
344 rows in our final dataset. The median number of sports balls found
in a dumpster in 2017 was 8

Additional data sheets include month precipitation data, in which:

  - There are a total of 24 rows in our final dataset that combine
    precipitation data for 2017 and 2018.
  - The total precipitation in 2018 was 70.33 inches.

# Question 2

### Part 1: Read and clean NYC Transit data

Retain line, station, name, station latitude / longitude, routes served,
entry, vending, entrance type, and ADA compliance

``` r
transit_df = 
    read_csv(
        "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>%
  mutate_at(vars(route1:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  ) %>%
  drop_na(route_name) %>%
  select(line:station_longitude, route_number, route_name, entry, vending, entrance_type, ada)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

### Part 2: Convert the entry variable from character to a logical variable

``` r
transit_df = 
  transit_df %>%
  mutate(entry = if_else(entry == "YES", TRUE, FALSE))
```

### Part 3: Write a short paragraph about this dataset

NYC Transit data contains information related to each entrance and exit
for each subway station in NYC. Data also include information on lines,
stations and routes. So far, my data cleaning steps include cleaning the
variable names, converting route from double to a character variable,
converting route from wide to long format and omitting rows that do not
include route-specific data, and finally, converting entry from
character to a logical variable. There are a total of 4270 rows x 10
columns in our final dataset. Data are tidy now.

### Part 4: Answer the following questions

1)  How many distinct stations are there?  
    There are 465 distinct stations.

2)  How many stations are ADA compliant?  
    There are 84 stations that are ADA compliant.

3)  What proportion of station entrances / exits without vending allow
    entrance?  
    0.310962 of station entrances / exits without vending allow
    entrance.

4)  How many distinct stations serve the A train?  
    60 distinct stations serve the A train.

5)  Of the stations that serve the A train, how many are ADA
    compliant?  
    Of the stations that serve the A train, 17 are ADA compliant.

# Question 3

### Part 1: Read and clean data in pols-month.csv

1)  Break up the variable mon into integer variables year, month, and
    day
2)  Replace month number with month name
3)  Create a president variable taking values gop and dem, and remove
    prez\_dem and prez\_gop
4)  Remove the day variable

<!-- end list -->

``` r
pols_df = 
    read_csv(
        "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
month_df = 
    tibble(
        month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
        month_name = month.name
    )

pols_df =
    left_join(pols_df, month_df, by = "month")  %>%
  mutate(month = month_name) %>%
  select(-month_name) %>%
  mutate(president = case_when(prez_gop == 1 ~ "gop", prez_dem == 1 ~ "dem")) %>%
  select(-c(prez_gop, prez_dem, day)) %>%
  relocate(year, month, president)
```

### Part 2: Read and clean data in snp.csv

For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_df = 
    read_csv(
        "./data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year")) %>%
  select(-day) %>% 
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
month_df = 
    tibble(
        month = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"),
        month_name = month.name
    )

snp_df =
    left_join(snp_df, month_df, by = "month")  %>%
  mutate(month = month_name) %>%
  select(-month_name)
```

### Part 3: Read and clean data in unemployment.csv

1)  Switching from “wide” to “long” format
2)  Ensuring that key variables have the same name
3)  Ensuring that key variables take the same values.

<!-- end list -->

``` r
unemp_df = 
    read_csv(
        "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_pct"
  ) %>%
  rename(year = Year) %>% 
  mutate(year = as.character(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
month_df = 
    tibble(
        month = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"),
        month_name = month.name
    )

unemp_df =
    left_join(unemp_df, month_df, by = "month")  %>%
  mutate(month = month_name) %>%
  select(-month_name)
```

### Part 4: Join the datasets by merging snp into pols, and merging unemployment into the result

``` r
pols_snp_df =
    left_join(pols_df, snp_df, by = c("year", "month"))

pols_snp_unemp_df =
  left_join(pols_snp_df, unemp_df, by = c("year", "month"))  %>% view
```

### Part 5: Write a short paragraph about these datasets

My result dataset was joined by three datasets, which were merged by
*year* and *month*: pols-month, snp, and unemployment. Before merging
the datasets, I made sure that the formats and data types of *year* and
*month* variables were consistent across all three datasets. pols-month
dataset contains the number of national politicians who are democratic
or republican at given time. The indicators of whether the president was
democratic or republican on the associated date were recoded by a new
variable called *president*. snp dataset contains variable *close*,
which are the closing values of the S\&P stock index on the associated
date. umemployment dataset contains *unemployment\_pct*, which indicates
the percentage of unemployment at given time. There are a total of 822
rows x 11 columns in our final dataset.The range of *year* is \[1947,
2015\].
